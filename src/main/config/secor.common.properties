# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

############
# MUST SET #
############

# Regular expression matching names of consumed topics.
secor.kafka.topic_filter=.*

# AWS authentication credentials.
aws.access.key=
aws.secret.key=

################
# END MUST SET #
################

# Zookeeper config.
zookeeper.session.timeout.ms=3000
zookeeper.sync.time.ms=200

# Impacts how frequently the upload logic is triggered if no messages are delivered.
kafka.consumer.timeout.ms=10000

# Max number of retries during rebalance.
kafka.rebalance.max.retries=

# Rebalance backoff.
kafka.rebalance.backoff.ms=

# Kafka consumer receive buffer size (socket.receive.buffer.bytes)
kafka.socket.receive.buffer.bytes=

# Kafka fetch max size (fetch.message.max.bytes)
kafka.fetch.message.max.bytes=

# Port of the broker serving topic partition metadata.
kafka.seed.broker.port=9092

# Zookeeper path at which kafka is registered. In Zookeeper parlance, this is referred
# to as the chroot.
kafka.zookeeper.path=/

# Secor generation is a version that should be incremented during non-backwards-compabile
# Secor releases. Generation number is one of the components of generated log file names.
# Generation number makes sure that outputs of different Secor versions are isolated.
secor.generation=1

# Number of consumer threads per Secor process.
secor.consumer.threads=7

# Consumption rate limit enforced at the process level (not a consumer-thread level).
secor.messages.per.second=10000

# Used by the "backup" consumer group only.
# Number of continous message offsets that constitute a single offset= partition on s3.
# Example:
#   if set to 10,
#     messages with offsets 0 to 9 will be written to s3 path s3n://.../offset=0/...
#     messages with offsets 10 to 19 will be written to s3 path s3n://.../offset=10/...
#     ...
secor.offsets.per.partition=10000000

# How long does it take for secor to forget a topic partition. Applies to stats generation only.
secor.topic_partition.forget.seconds=600

# If greater than 0, upon starup Secor will clean up directories and files under secor.local.path
# that are older than this value.
secor.local.log.delete.age.hours=-1

# Secor comes with a tool that adds Hive partitions for finalized topics. Currently, we support
# only Hive clusters accessible through Qubole. The token gives access to the Qubole API.
# It is available at https://api.qubole.com/users/edit
qubole.api.token=

# Secor can export stats such as consumption lag (in seconds and offsets) per topic partition.
# Leave empty to disable this functionality.
tsdb.hostport=

# Regex of topics that are not exported to TSDB.
monitoring.blacklist.topics=

# Secor can export stats to statsd such as consumption lag (in seconds and offsets) per topic partition.
# Leave empty to disable this functionality.
statsd.hostport=

# Name of field that contains timestamp for JSON, MessagePack, or Thrift message parser. (1405970352123)
message.timestamp.name=timestamp

# Name of field that contains a timestamp, as a date Format, for JSON. (2014-08-07, Jul 23 02:16:57 2005, etc...)
# Should be used when there is no timestamp in a Long format. Also ignore time zones.
message.timestamp.input.pattern=

# To enable compression, set this to a valid compression codec, such as 'org.apache.hadoop.io.compress.GzipCodec'.
secor.compression.codec=

# The secor file reader/writer used to read/write the data, by default we write sequence files
secor.file.reader.writer=com.pinterest.secor.io.impl.SequenceFileReaderWriter

# Max message size in bytes to retrieve via KafkaClient. This is used by ProgressMonitor and PartitionFinalizer.
# This should be set large enough to accept the max message size configured in your kafka broker
# Default is 0.1 MB
secor.max.message.size.bytes=100000
